# Unitary Sparsifying Transform Learning
Image Denoising Codes using Unitary Transform Learning, the Matlab implementation.

This implementation is used in the following paper: 

"When Sparsity Meets Low-Rankness: Transform Learning With Non-Local Low-Rank Constraint for Image Restoration", IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2017. [[ICASSP 2017](http://ieeexplore.ieee.org/abstract/document/7952566/)], [[PDF available](http://transformlearning.csl.illinois.edu/assets/Bihan/ConferencePapers/BihanICASSP2017strollr.pdf)], [[Code](https://github.com/wenbihan/unitary_transform_learning)], [[STROLLR] (https://github.com/wenbihan/strollr2d_icassp2017)].


Description:
-----

Learn unitary sparsifying transform directly from the noisy image, and use it for image denoising.
The algorithm has exact solution for each step, which is very fast.

You can download our other software packages at: [My Homepage](http://web.engr.illinois.edu/~bwen3/) and [Transform Learning Site](http://transformlearning.csl.illinois.edu/).

Paper

In case of use, please cite our publications:

B. Wen, Y. Li, and Y. Bresler, “When Sparsity Meets Low-Rankness: Transform Learning With Non-Local Low-Rank Constraint for Image Restoration,” in Proc. IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2017.

```
@inproceedings{wen2017strollr2d,
  title  	= {When sparsity meets low-rankness: Transform learning with non-local low-rank constraint for image restoration},
  author 	= {Wen, Bihan and Li, Yanjun and Bresler, Yoram},
  booktitle = {IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages 	= {2297--2301},
  year 		= {2017},
  organization={IEEE}
}
```

Use
---
All codes are subject to copyright and may only be used for non-commercial research. In case of use, please cite our publication.

Contact Bihan Wen (bihan.wen.uiuc@gmail.com) for any questions.

Acknowledgement
---
The development of this software was supported in part by the National Science Foundation (NSF) under grants CCF 06-35234 and CCF 10-18660.